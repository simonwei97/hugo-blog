<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>æ¨¡å‹è®­ç»ƒ | Simon&#39;s Blog</title>
<meta name="keywords" content="LLM, model, train, torch">
<meta name="description" content="Model Train from PyTorch DDP to Accelerate and Trainer.">
<meta name="author" content="Simon Wei">
<link rel="canonical" href="http://localhost:1313/zh/posts/model_train/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5337419bf91ee8eb68d3ca5238354e6d4f70e008bc270a39f496e03c9b357e05.css" integrity="sha256-UzdBm/ke6Oto08pSODVObU9w4Ai8Jwo59JbgPJs1fgU=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/model_train/">
<link rel="alternate" hreflang="zh" href="http://localhost:1313/zh/posts/model_train/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>



  

<meta property="og:title" content="æ¨¡å‹è®­ç»ƒ" />
<meta property="og:description" content="Model Train from PyTorch DDP to Accelerate and Trainer." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/zh/posts/model_train/" />
<meta property="og:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-03-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-03-10T00:00:00+00:00" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta name="twitter:title" content="æ¨¡å‹è®­ç»ƒ"/>
<meta name="twitter:description" content="Model Train from PyTorch DDP to Accelerate and Trainer."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/zh/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "æ¨¡å‹è®­ç»ƒ",
      "item": "http://localhost:1313/zh/posts/model_train/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "æ¨¡å‹è®­ç»ƒ",
  "name": "æ¨¡å‹è®­ç»ƒ",
  "description": "Model Train from PyTorch DDP to Accelerate and Trainer.",
  "keywords": [
    "LLM", "model", "train", "torch"
  ],
  "articleBody": "æ¦‚è¿° æœ¬æ•™ç¨‹å‡å®šä½ å·²ç»å¯¹äº PyToch è®­ç»ƒä¸€ä¸ªç®€å•æ¨¡å‹æœ‰ä¸€å®šçš„åŸºç¡€ç†è§£ã€‚æœ¬æ•™ç¨‹å°†å±•ç¤ºä½¿ç”¨ 3 ç§å°è£…å±‚çº§ä¸åŒçš„æ–¹æ³•è°ƒç”¨ DDP (DistributedDataParallel) è¿›ç¨‹ï¼Œåœ¨å¤šä¸ª GPU ä¸Šè®­ç»ƒåŒä¸€ä¸ªæ¨¡å‹ï¼š\nä½¿ç”¨ pytorch.distributed æ¨¡å—çš„åŸç”Ÿ PyTorch DDP æ¨¡å— ä½¿ç”¨ ğŸ¤— Accelerate å¯¹ pytorch.distributed çš„è½»é‡å°è£…ï¼Œç¡®ä¿ç¨‹åºå¯ä»¥åœ¨ä¸ä¿®æ”¹ä»£ç æˆ–è€…å°‘é‡ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹åœ¨å•ä¸ª GPU æˆ– TPU ä¸‹æ­£å¸¸è¿è¡Œ ä½¿ç”¨ ğŸ¤— Transformers çš„é«˜çº§ Trainer API ï¼Œè¯¥ API æŠ½è±¡å°è£…äº†æ‰€æœ‰ä»£ç æ¨¡æ¿å¹¶ä¸”æ”¯æŒä¸åŒè®¾å¤‡å’Œåˆ†å¸ƒå¼åœºæ™¯ã€‚ æç¤º\nThis is a very good tip.\næ³¨é‡Š\nThis is a very good tip.\nä¿¡æ¯\nThis is a very good tip.\nè­¦å‘Š\nThis is a very good tip.\nThis is a very good tip.\nPyTorch DDP import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets, transforms class BasicNet(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 32, 3, 1) self.conv2 = nn.Conv2d(32, 64, 3, 1) self.dropout1 = nn.Dropout(0.25) self.dropout2 = nn.Dropout(0.5) self.fc1 = nn.Linear(9216, 128) self.fc2 = nn.Linear(128, 10) self.act = F.relu def forward(self, x): x = self.act(self.conv1(x)) x = self.act(self.conv2(x)) x = F.max_pool2d(x, 2) x = self.dropout1(x) x = torch.flatten(x, 1) x = self.act(self.fc1(x)) x = self.dropout2(x) x = self.fc2(x) output = F.log_softmax(x, dim=1) return output æˆ‘ä»¬å®šä¹‰è®­ç»ƒè®¾å¤‡ (cuda):\ndevice = \"cuda\" æ„å»ºä¸€äº›åŸºæœ¬çš„ PyTorch DataLoaders:\nfrom torchvision import datasets, transforms transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307), (0.3081)) ]) train_dset = datasets.MNIST('data', train=True, download=True, transform=transform) test_dset = datasets.MNIST('data', train=False, transform=transform) train_loader = torch.utils.data.DataLoader(train_dset, shuffle=True, batch_size=64) test_loader = torch.utils.data.DataLoader(test_dset, shuffle=False, batch_size=64) æŠŠæ¨¡å‹æ”¾å…¥ CUDA è®¾å¤‡:\nmodel = BasicNet().to(device) æ„å»º PyTorch optimizer (ä¼˜åŒ–å™¨)\noptimizer = optim.AdamW(model.parameters(), lr=1e-3) æœ€ç»ˆåˆ›å»ºä¸€ä¸ªç®€å•çš„è®­ç»ƒå’Œè¯„ä¼°å¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯ä¼šä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¯„ä¼°å¾ªç¯ä¼šè®¡ç®—è®­ç»ƒåæ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„å‡†ç¡®åº¦ï¼š\nmodel.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() optimizer.zero_grad() model.eval() correct = 0 with torch.no_grad(): for data, target in test_loader: output = model(data) pred = output.argmax(dim=1, keepdim=True) correct += pred.eq(target.view_as(pred)).sum().item() print(f'Accuracy: {100. * correct / len(test_loader.dataset)}') é€šå¸¸ä»è¿™é‡Œå¼€å§‹ï¼Œå°±å¯ä»¥å°†æ‰€æœ‰çš„ä»£ç æ”¾å…¥ Python è„šæœ¬æˆ–åœ¨ Jupyter Notebook ä¸Šè¿è¡Œå®ƒã€‚\nç„¶è€Œï¼Œåªæ‰§è¡Œ python myscript.py åªä¼šä½¿ç”¨å•ä¸ª GPU è¿è¡Œè„šæœ¬ã€‚å¦‚æœæœ‰å¤šä¸ª GPU èµ„æºå¯ç”¨ï¼Œæ‚¨å°†å¦‚ä½•è®©è¿™ä¸ªè„šæœ¬åœ¨ä¸¤ä¸ª GPU æˆ–å¤šå°æœºå™¨ä¸Šè¿è¡Œï¼Œé€šè¿‡åˆ†å¸ƒå¼è®­ç»ƒæé«˜è®­ç»ƒé€Ÿåº¦ï¼Ÿè¿™æ˜¯ torch.distributed å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚\nFig. 1. An overview of threats to LLM-based applications. GPU\nPyTorch åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ é¡¾åæ€ä¹‰ï¼Œtorch.distributed æ—¨åœ¨é…ç½®åˆ†å¸ƒå¼è®­ç»ƒã€‚ä½ å¯ä»¥ä½¿ç”¨å®ƒé…ç½®å¤šä¸ªèŠ‚ç‚¹è¿›è¡Œè®­ç»ƒï¼Œä¾‹å¦‚ï¼šå¤šæœºå™¨ä¸‹çš„å•ä¸ª GPUï¼Œæˆ–è€…å•å°æœºå™¨ä¸‹çš„å¤šä¸ª GPUï¼Œæˆ–è€…ä¸¤è€…çš„ä»»æ„ç»„åˆã€‚\nä¸ºäº†å°†ä¸Šè¿°ä»£ç è½¬æ¢ä¸ºåˆ†å¸ƒå¼è®­ç»ƒï¼Œå¿…é¡»é¦–å…ˆå®šä¹‰ä¸€äº›è®¾ç½®é…ç½®ï¼Œå…·ä½“ç»†èŠ‚è¯·å‚é˜… DDP ä½¿ç”¨æ•™ç¨‹ã€‚\né¦–å…ˆå¿…é¡»å£°æ˜ setup å’Œ cleanup å‡½æ•°ã€‚è¿™å°†åˆ›å»ºä¸€ä¸ªè¿›ç¨‹ç»„ï¼Œå¹¶ä¸”æ‰€æœ‰è®¡ç®—è¿›ç¨‹éƒ½å¯ä»¥é€šè¿‡è¿™ä¸ªè¿›ç¨‹ç»„é€šä¿¡ã€‚\næ³¨æ„ï¼šåœ¨æœ¬æ•™ç¨‹çš„è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œå‡å®šè¿™äº›ä»£ç æ˜¯åœ¨ Python è„šæœ¬æ–‡ä»¶ä¸­å¯åŠ¨ã€‚ç¨åå°†è®¨è®ºä½¿ç”¨ ğŸ¤— Accelerate çš„å¯åŠ¨å™¨ï¼Œå°±ä¸å¿…å£°æ˜ setup å’Œ cleanup å‡½æ•°äº†\nğŸ¤— Accelerate ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªåº“ï¼Œæ—¨åœ¨æ— éœ€å¤§å¹…ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹å®Œæˆå¹¶è¡ŒåŒ–ã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒğŸ¤— Accelerate é™„å¸¦çš„æ•°æ® pipeline è¿˜å¯ä»¥æé«˜ä»£ç çš„æ€§èƒ½ã€‚\né¦–å…ˆï¼Œè®©æˆ‘ä»¬å°†åˆšåˆšæ‰§è¡Œçš„æ‰€æœ‰ä¸Šè¿°ä»£ç å°è£…åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬ç›´è§‚åœ°çœ‹åˆ°å·®å¼‚ï¼š\ndef train_ddp(rank, world_size): setup(rank, world_size) # Build DataLoaders transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307), (0.3081)) ]) train_dset = datasets.MNIST('data', train=True, download=True, transform=transform) test_dset = datasets.MNIST('data', train=False, transform=transform) train_loader = torch.utils.data.DataLoader(train_dset, shuffle=True, batch_size=64) test_loader = torch.utils.data.DataLoader(test_dset, shuffle=False, batch_size=64) # Build model model = model.to(rank) ddp_model = DDP(model, device_ids=[rank]) # Build optimizer optimizer = optim.AdamW(ddp_model.parameters(), lr=1e-3) # Train for a single epoch model.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() optimizer.zero_grad() # Evaluate model.eval() correct = 0 with torch.no_grad(): for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) pred = output.argmax(dim=1, keepdim=True) correct += pred.eq(target.view_as(pred)).sum().item() print(f'Accuracy: {100. * correct / len(test_loader.dataset)}') - device = 'cuda' + device = accelerator.device - inputs = inputs.to(device) - targets = targets.to(device) outputs = model(inputs) loss = loss_function(outputs, targets) - loss.backward() + accelerator.backward(loss) Attack Type Description Token manipulation Black-box Alter a small fraction of tokens in the text input such that it triggers model failure but still remain its original semantic meanings. Gradient based attack White-box Rely on gradient signals to learn an effective attack. Jailbreak prompting Black-box Often heuristic based prompting to â€œjailbreakâ€ built-in model safety. Human red-teaming Black-box Human attacks the model, with or without assist from other models. Model red-teaming Black-box Model attacks the model, where the attacker model can be fine-tuned. æµ‹è¯•\\(\\tilde{a}\\)ä½ å¥½ $$ \\overbrace{a+b+c}^{\\text{note}} $$\n",
  "wordCount" : "1192",
  "inLanguage": "zh",
  "image": "http://localhost:1313/images/papermod-cover.png","datePublished": "2019-03-10T00:00:00Z",
  "dateModified": "2019-03-10T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Simon Wei"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/zh/posts/model_train/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Simon's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/zh/" accesskey="h" title="Simon&#39;s Blog (Alt + H)">Simon&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://localhost:1313/" title="ğŸ‡ºğŸ‡¸ EN"
                            aria-label="ğŸ‡ºğŸ‡¸ EN">ğŸ‡ºğŸ‡¸ EN</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/zh/" title="ğŸ“š åšå®¢">
                    <span>ğŸ“š åšå®¢</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/zh/archives" title="ğŸ§± å½’æ¡£">
                    <span>ğŸ§± å½’æ¡£</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/zh/search/" title="ğŸ” æœç´¢">
                    <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/zh/tags/" title="ğŸ§© æ ‡ç­¾">
                    <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://simonwei97.github.io/" title="å›åˆ°ä¸»é¡µ">
                    <span>å›åˆ°ä¸»é¡µ</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/zh/">ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/zh/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      æ¨¡å‹è®­ç»ƒ
    </h1>
    <div class="post-description">
      Model Train from PyTorch DDP to Accelerate and Trainer.
    </div>
    <div class="post-meta">æ—¥æœŸ:&nbsp;<span title='2019-03-10 00:00:00 +0000 UTC'>ä¸‰æœˆ 10, 2019</span>&nbsp;|&nbsp;é¢„ä¼°é˜…è¯»æ—¶é—´:&nbsp;3 åˆ†é’Ÿ&nbsp;|&nbsp;ä½œè€…:&nbsp;Simon Wei&nbsp;|&nbsp;è¯­è¨€:
<ul class="i18n_list">
    <li>
        <a href="http://localhost:1313/posts/model_train/">ğŸ‡ºğŸ‡¸ EN</a>
    </li>
</ul>

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e6%a6%82%e8%bf%b0" aria-label="æ¦‚è¿°">æ¦‚è¿°</a><ul>
                        
                <li>
                    <a href="#pytorch-ddp" aria-label="PyTorch DDP">PyTorch DDP</a></li></ul>
                </li>
                <li>
                    <a href="#pytorch-%e5%88%86%e5%b8%83%e5%bc%8f%e6%95%b0%e6%8d%ae%e5%b9%b6%e8%a1%8c" aria-label="PyTorch åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ">PyTorch åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ</a></li>
                <li>
                    <a href="#hugs-accelerate" aria-label="&amp;#x1f917; Accelerate">&#x1f917; Accelerate</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        if (elements) {
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                    (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                    return element;
                }
            }) || activeElement

            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                if (element === activeElement){
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
                } else {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
                }
            })
        }
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
  <div class="post-content"><h1 id="æ¦‚è¿°">æ¦‚è¿°<a hidden class="anchor" aria-hidden="true" href="#æ¦‚è¿°">#</a></h1>
<p>æœ¬æ•™ç¨‹å‡å®šä½ å·²ç»å¯¹äº <strong>PyToch</strong> è®­ç»ƒä¸€ä¸ªç®€å•æ¨¡å‹æœ‰ä¸€å®šçš„åŸºç¡€ç†è§£ã€‚æœ¬æ•™ç¨‹å°†å±•ç¤ºä½¿ç”¨ 3 ç§å°è£…å±‚çº§ä¸åŒçš„æ–¹æ³•è°ƒç”¨ <code>DDP (DistributedDataParallel)</code> è¿›ç¨‹ï¼Œåœ¨å¤šä¸ª GPU ä¸Šè®­ç»ƒåŒä¸€ä¸ªæ¨¡å‹ï¼š</p>
<ol>
<li>ä½¿ç”¨ <code>pytorch.distributed</code> æ¨¡å—çš„åŸç”Ÿ <strong>PyTorch DDP</strong> æ¨¡å—</li>
<li>ä½¿ç”¨ <a href="https://github.com/huggingface/accelerate">&#x1f917; Accelerate</a> å¯¹ <code>pytorch.distributed</code> çš„è½»é‡å°è£…ï¼Œç¡®ä¿ç¨‹åºå¯ä»¥åœ¨ä¸ä¿®æ”¹ä»£ç æˆ–è€…å°‘é‡ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹åœ¨å•ä¸ª GPU æˆ– TPU ä¸‹æ­£å¸¸è¿è¡Œ</li>
<li>ä½¿ç”¨ <a href="https://github.com/huggingface/transformers">&#x1f917; Transformers</a> çš„é«˜çº§ <code>Trainer API</code> ï¼Œè¯¥ API æŠ½è±¡å°è£…äº†æ‰€æœ‰ä»£ç æ¨¡æ¿å¹¶ä¸”æ”¯æŒä¸åŒè®¾å¤‡å’Œåˆ†å¸ƒå¼åœºæ™¯ã€‚</li>
</ol>
<style type="text/css">
     
    .notice {
        --title-color: #fff;
        --title-background-color: #6be;
        --content-color: #444;
        --content-background-color: #e7f2fa;
    }

    .notice.info {
        --title-background-color: #fb7;
        --content-background-color: #fec;
    }

    .notice.tip {
        --title-background-color: #5a5;
        --content-background-color: #efe;
    }

    .notice.warning {
        --title-background-color: #c33;
        --content-background-color: #fee;
    }

     
    @media (prefers-color-scheme:dark) {
        .notice {
            --title-color: #fff;
            --title-background-color: #069;
            --content-color: #ddd;
            --content-background-color: #023;
        }

        .notice.info {
            --title-background-color: #a50;
            --content-background-color: #420;
        }

        .notice.tip {
            --title-background-color: #363;
            --content-background-color: #121;
        }

        .notice.warning {
            --title-background-color: #800;
            --content-background-color: #400;
        }
    }

    body.dark .notice {
        --title-color: #fff;
        --title-background-color: #069;
        --content-color: #ddd;
        --content-background-color: #023;
    }

    body.dark .notice.info {
        --title-background-color: #a50;
        --content-background-color: #420;
    }

    body.dark .notice.tip {
        --title-background-color: #363;
        --content-background-color: #121;
    }

    body.dark .notice.warning {
        --title-background-color: #800;
        --content-background-color: #400;
    }

     
    .notice {
        padding: 18px;
        line-height: 24px;
        margin-bottom: 24px;
        border-radius: 4px;
        color: var(--content-color);
        background: var(--content-background-color);
        box-shadow: 3px 3px 5px #0089e410;
    }

    .notice p:last-child {
        margin-bottom: 0
    }

     
    .notice-title {
        margin: -18px -18px 12px;
        padding: 4px 18px;
        border-radius: 4px 4px 0 0;
        font-weight: 700;
        color: var(--title-color);
        background: var(--title-background-color);
    }

     
    .icon-notice {
        display: inline-flex;
        align-self: center;
        margin-right: 8px;
    }

    .icon-notice img,
    .icon-notice svg {
        height: 1em;
        width: 1em;
        fill: currentColor;
    }

    .icon-notice img,
    .icon-notice.baseline svg {
        top: .125em;
        position: relative;
    }
</style><div class="notice tip" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="300.5 134 300 300">
  <path d="M551.281 252.36c0-3.32-1.172-6.641-3.515-8.985l-17.774-17.578c-2.344-2.344-5.469-3.711-8.789-3.711-3.32 0-6.445 1.367-8.789 3.71l-79.687 79.493-44.141-44.14c-2.344-2.344-5.469-3.712-8.79-3.712-3.32 0-6.444 1.368-8.788 3.711l-17.774 17.579c-2.343 2.343-3.515 5.664-3.515 8.984 0 3.32 1.172 6.445 3.515 8.789l70.704 70.703c2.343 2.344 5.664 3.711 8.789 3.711 3.32 0 6.64-1.367 8.984-3.71l106.055-106.056c2.343-2.343 3.515-5.468 3.515-8.789ZM600.5 284c0 82.813-67.188 150-150 150-82.813 0-150-67.188-150-150 0-82.813 67.188-150 150-150 82.813 0 150 67.188 150 150Z"/>
</svg>
        </span>æç¤º</p><p>This is a very good tip.</p></div>



<div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>
        </span>æ³¨é‡Š</p><p>This is a very good tip.</p></div>



<div class="notice info" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="92 59.5 300 300">
  <path d="M292 303.25V272c0-3.516-2.734-6.25-6.25-6.25H267v-100c0-3.516-2.734-6.25-6.25-6.25h-62.5c-3.516 0-6.25 2.734-6.25 6.25V197c0 3.516 2.734 6.25 6.25 6.25H217v62.5h-18.75c-3.516 0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h87.5c3.516 0 6.25-2.734 6.25-6.25Zm-25-175V97c0-3.516-2.734-6.25-6.25-6.25h-37.5c-3.516 0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h37.5c3.516 0 6.25-2.734 6.25-6.25Zm125 81.25c0 82.813-67.188 150-150 150-82.813 0-150-67.188-150-150 0-82.813 67.188-150 150-150 82.813 0 150 67.188 150 150Z"/>
</svg>
        </span>ä¿¡æ¯</p><p>This is a very good tip.</p></div>



<div class="notice warning" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="126 76.5 300 300">
  <path d="M297.431 324.397v-34.255c0-3.245-2.344-5.95-5.358-5.95h-32.146c-3.014 0-5.358 2.705-5.358 5.95v34.255c0 3.245 2.344 5.95 5.358 5.95h32.146c3.014 0 5.358-2.705 5.358-5.95Zm-.335-67.428 3.014-82.753c0-1.081-.502-2.524-1.674-3.425-1.005-.902-2.512-1.983-4.019-1.983h-36.834c-1.507 0-3.014 1.081-4.019 1.983-1.172.901-1.674 2.704-1.674 3.786l2.846 82.392c0 2.344 2.512 4.146 5.693 4.146h30.975c3.013 0 5.525-1.803 5.692-4.146Zm-2.344-168.39L423.34 342.425c3.683 7.032 3.516 15.686-.335 22.717-3.85 7.031-10.883 11.358-18.417 11.358H147.413c-7.534 0-14.566-4.327-18.417-11.358-3.85-7.031-4.018-15.685-.335-22.716L257.248 88.578C260.93 81.188 268.13 76.5 276 76.5c7.87 0 15.069 4.688 18.752 12.08Z"/>
</svg>
        </span>è­¦å‘Š</p><p>This is a very good tip.</p></div>



<blockquote>
<p>This is a very good tip.</p>
</blockquote>
<h2 id="pytorch-ddp">PyTorch DDP<a hidden class="anchor" aria-hidden="true" href="#pytorch-ddp">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">BasicNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span>
</span></span></code></pre></div><p>æˆ‘ä»¬å®šä¹‰è®­ç»ƒè®¾å¤‡ (cuda):</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="s2">&#34;cuda&#34;</span>
</span></span></code></pre></div><p>æ„å»ºä¸€äº›åŸºæœ¬çš„ <code>PyTorch DataLoaders</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_dset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_dset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</span></span></code></pre></div><p>æŠŠæ¨¡å‹æ”¾å…¥ <code>CUDA</code> è®¾å¤‡:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">BasicNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span></code></pre></div><p>æ„å»º <code>PyTorch optimizer</code> (ä¼˜åŒ–å™¨)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</span></span></code></pre></div><p>æœ€ç»ˆåˆ›å»ºä¸€ä¸ªç®€å•çš„è®­ç»ƒå’Œè¯„ä¼°å¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯ä¼šä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¯„ä¼°å¾ªç¯ä¼šè®¡ç®—è®­ç»ƒåæ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„å‡†ç¡®åº¦ï¼š</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy: </span><span class="si">{</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>é€šå¸¸ä»è¿™é‡Œå¼€å§‹ï¼Œå°±å¯ä»¥å°†æ‰€æœ‰çš„ä»£ç æ”¾å…¥ Python è„šæœ¬æˆ–åœ¨ Jupyter Notebook ä¸Šè¿è¡Œå®ƒã€‚</p>
<p>ç„¶è€Œï¼Œåªæ‰§è¡Œ <code>python myscript.py</code> åªä¼šä½¿ç”¨å•ä¸ª GPU è¿è¡Œè„šæœ¬ã€‚å¦‚æœæœ‰å¤šä¸ª GPU èµ„æºå¯ç”¨ï¼Œæ‚¨å°†å¦‚ä½•è®©è¿™ä¸ªè„šæœ¬åœ¨ä¸¤ä¸ª GPU æˆ–å¤šå°æœºå™¨ä¸Šè¿è¡Œï¼Œé€šè¿‡åˆ†å¸ƒå¼è®­ç»ƒæé«˜è®­ç»ƒé€Ÿåº¦ï¼Ÿè¿™æ˜¯ <code>torch.distributed</code> å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚</p>
<!-- ![](/img/gpu.png) -->
<!-- <figure class="align-center "><a href="https://unsplash.com/photos/Z0lL0okYjy0" target="_blank">
    <img loading="lazy" src="https://source.unsplash.com/Z0lL0okYjy0#center"/> </a><figcaption>
            <p>Photo by <a href="https://unsplash.com/@adityatelange?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Aditya Telange</a> on <a href="https://unsplash.com/photos/Z0lL0okYjy0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a></p>
        </figcaption>
</figure>
 -->
<figure class="align-center ">
    <img loading="lazy" src="/img/gpu.png#center"/> <figcaption>
            <p>Fig. 1. An overview of threats to LLM-based applications. GPU</p>
        </figcaption>
</figure>

<h1 id="pytorch-åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ">PyTorch åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ<a hidden class="anchor" aria-hidden="true" href="#pytorch-åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ">#</a></h1>
<p>é¡¾åæ€ä¹‰ï¼Œ<code>torch.distributed</code> æ—¨åœ¨é…ç½®åˆ†å¸ƒå¼è®­ç»ƒã€‚ä½ å¯ä»¥ä½¿ç”¨å®ƒé…ç½®å¤šä¸ªèŠ‚ç‚¹è¿›è¡Œè®­ç»ƒï¼Œä¾‹å¦‚ï¼šå¤šæœºå™¨ä¸‹çš„å•ä¸ª GPUï¼Œæˆ–è€…å•å°æœºå™¨ä¸‹çš„å¤šä¸ª GPUï¼Œæˆ–è€…ä¸¤è€…çš„ä»»æ„ç»„åˆã€‚</p>
<p>ä¸ºäº†å°†ä¸Šè¿°ä»£ç è½¬æ¢ä¸ºåˆ†å¸ƒå¼è®­ç»ƒï¼Œå¿…é¡»é¦–å…ˆå®šä¹‰ä¸€äº›è®¾ç½®é…ç½®ï¼Œå…·ä½“ç»†èŠ‚è¯·å‚é˜… DDP ä½¿ç”¨æ•™ç¨‹ã€‚</p>
<p>é¦–å…ˆå¿…é¡»å£°æ˜ <code>setup</code> å’Œ <code>cleanup</code> å‡½æ•°ã€‚è¿™å°†åˆ›å»ºä¸€ä¸ªè¿›ç¨‹ç»„ï¼Œå¹¶ä¸”æ‰€æœ‰è®¡ç®—è¿›ç¨‹éƒ½å¯ä»¥é€šè¿‡è¿™ä¸ªè¿›ç¨‹ç»„é€šä¿¡ã€‚</p>
<blockquote>
<p>æ³¨æ„ï¼šåœ¨æœ¬æ•™ç¨‹çš„è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œå‡å®šè¿™äº›ä»£ç æ˜¯åœ¨ Python è„šæœ¬æ–‡ä»¶ä¸­å¯åŠ¨ã€‚ç¨åå°†è®¨è®ºä½¿ç”¨ &#x1f917; <code>Accelerate</code> çš„å¯åŠ¨å™¨ï¼Œå°±ä¸å¿…å£°æ˜ <code>setup</code> å’Œ <code>cleanup</code> å‡½æ•°äº†</p>
</blockquote>
<h1 id="hugs-accelerate">&#x1f917; Accelerate<a hidden class="anchor" aria-hidden="true" href="#hugs-accelerate">#</a></h1>
<p>&#x1f917; <code>Accelerate</code> æ˜¯ä¸€ä¸ªåº“ï¼Œæ—¨åœ¨æ— éœ€å¤§å¹…ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹å®Œæˆå¹¶è¡ŒåŒ–ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œ&#x1f917; Accelerate é™„å¸¦çš„æ•°æ® pipeline è¿˜å¯ä»¥æé«˜ä»£ç çš„æ€§èƒ½ã€‚</p>
<p>é¦–å…ˆï¼Œè®©æˆ‘ä»¬å°†åˆšåˆšæ‰§è¡Œçš„æ‰€æœ‰ä¸Šè¿°ä»£ç å°è£…åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬ç›´è§‚åœ°çœ‹åˆ°å·®å¼‚ï¼š</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_ddp</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">setup</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Build DataLoaders</span>
</span></span><span class="line"><span class="cl">    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">train_dset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_dset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Build model</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ddp_model</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Build optimizer</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">ddp_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Train for a single epoch</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Evaluate</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy: </span><span class="si">{</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"><span class="gd">-   device = &#39;cuda&#39;
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+   device = accelerator.device
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"><span class="gd">-   inputs = inputs.to(device)
</span></span></span><span class="line"><span class="cl"><span class="gd">-   targets = targets.to(device)
</span></span></span><span class="line"><span class="cl"><span class="gd"></span>    outputs = model(inputs)
</span></span><span class="line"><span class="cl">    loss = loss_function(outputs, targets)
</span></span><span class="line"><span class="cl"><span class="gd">-   loss.backward()
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+   accelerator.backward(loss)
</span></span></span></code></pre></div><table>
<thead>
<tr>
<th>Attack</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Token manipulation</td>
<td>Black-box</td>
<td>Alter a small fraction of tokens in the text input such that it triggers model failure but still remain its original semantic meanings.</td>
</tr>
<tr>
<td>Gradient based attack</td>
<td>White-box</td>
<td>Rely on gradient signals to learn an effective attack.</td>
</tr>
<tr>
<td>Jailbreak prompting</td>
<td>Black-box</td>
<td>Often heuristic based prompting to â€œjailbreakâ€ built-in model safety.</td>
</tr>
<tr>
<td>Human red-teaming</td>
<td>Black-box</td>
<td>Human attacks the model, with or without assist from other models.</td>
</tr>
<tr>
<td>Model red-teaming</td>
<td>Black-box</td>
<td>Model attacks the model, where the attacker model can be fine-tuned.</td>
</tr>
</tbody>
</table>

æµ‹è¯•\(\tilde{a}\)ä½ å¥½

<p>$$
\overbrace{a+b+c}^{\text{note}}
$$</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/zh/tags/llm/">LLM</a></li>
      <li><a href="http://localhost:1313/zh/tags/model/">Model</a></li>
      <li><a href="http://localhost:1313/zh/tags/train/">Train</a></li>
      <li><a href="http://localhost:1313/zh/tags/torch/">Torch</a></li>
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>Â© <a href="https://simonwei97.github.io/">Simon&rsquo;s Blog</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerHTML = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerHTML = 'å¤åˆ¶';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
